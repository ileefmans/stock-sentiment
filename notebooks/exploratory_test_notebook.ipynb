{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/stock-sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ianleefmans/Desktop/stock-sentiment/utils')\n",
    "from data import Database, ScrapeWSB, Stock\n",
    "%cd /Users/ianleefmans/Desktop/stock-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 27, 19, 48, 52),)]\n",
      "[('COMMENTS',), ('POSTS',), ('STOCKS',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "\n",
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GME', datetime.datetime(2021, 5, 14, 1, 43, 41))]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SELECT * FROM STOCKS ;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nboe4x'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\",)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT TITLE FROM POSTS WHERE POST_ID='nboe4x'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT TITLE FROM POSTS WHERE POST_ID='{}'\".format(indexes[0][0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = db.query('''SELECT POST_ID FROM POSTS;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nboe4x',\n",
       "  'GME',\n",
       "  \"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\",\n",
       "  1276,\n",
       "  'wallstreetbets',\n",
       "  'https://i.redd.it/y6k4lkcjqxy61.jpg',\n",
       "  122,\n",
       "  '',\n",
       "  1620960000.0),\n",
       " ('nbjhc1',\n",
       "  'GME',\n",
       "  'YOLO: I switched jobs in January and just yolod my retirement into GME',\n",
       "  1535,\n",
       "  'wallstreetbets',\n",
       "  'https://i.redd.it/2k7ba30kqwy61.jpg',\n",
       "  192,\n",
       "  '',\n",
       "  1620950000.0),\n",
       " ('naruof',\n",
       "  'GME',\n",
       "  'Bought more GME cuz Iâ€™m retarded.',\n",
       "  5178,\n",
       "  'wallstreetbets',\n",
       "  'https://www.reddit.com/gallery/naruof',\n",
       "  431,\n",
       "  '',\n",
       "  1620860000.0),\n",
       " ('nat3xr',\n",
       "  'GME',\n",
       "  'Made 700k in GME in Jan. Then did this',\n",
       "  270,\n",
       "  'wallstreetbets',\n",
       "  'https://i.redd.it/ibx9k7mjwpy61.jpg',\n",
       "  173,\n",
       "  '',\n",
       "  1620870000.0),\n",
       " ('naha1d',\n",
       "  'GME',\n",
       "  '(O.C.) Keep shorting GME ðŸ¤¡',\n",
       "  672,\n",
       "  'wallstreetbets',\n",
       "  'https://v.redd.it/xqz6skpukmy61',\n",
       "  118,\n",
       "  '',\n",
       "  1620830000.0),\n",
       " ('n9yims',\n",
       "  'GME',\n",
       "  'Made a bit off apple and put some back into game stop. We at this side of the world is all for GME.',\n",
       "  1523,\n",
       "  'wallstreetbets',\n",
       "  'https://i.redd.it/vshenj3i6iy61.jpg',\n",
       "  102,\n",
       "  '',\n",
       "  1620770000.0),\n",
       " ('na2vt4',\n",
       "  'GME',\n",
       "  \"When applying the DDM on $GME's meme-dividend you'll arrive at a valuation of infinite tendies. Thin\",\n",
       "  353,\n",
       "  'wallstreetbets',\n",
       "  'https://v.redd.it/a6k3z3492jy61',\n",
       "  30,\n",
       "  '',\n",
       "  1620780000.0),\n",
       " ('n92bxl',\n",
       "  'GME',\n",
       "  'Reviewing my GME investment',\n",
       "  32862,\n",
       "  'wallstreetbets',\n",
       "  'https://v.redd.it/xiy8kdyl4ay61',\n",
       "  904,\n",
       "  '',\n",
       "  1620680000.0),\n",
       " ('n99m2y',\n",
       "  'GME',\n",
       "  'GME Great investment! Bought 600 more shares on my second account. 1600 shares in total! Life is gre',\n",
       "  12078,\n",
       "  'wallstreetbets',\n",
       "  'https://www.reddit.com/gallery/n99m2y',\n",
       "  972,\n",
       "  '',\n",
       "  1620690000.0),\n",
       " ('n8u8ao',\n",
       "  'GME',\n",
       "  \"Spongebob's Take on GME\",\n",
       "  8885,\n",
       "  'wallstreetbets',\n",
       "  'https://v.redd.it/crmkopiik7y61',\n",
       "  170,\n",
       "  '',\n",
       "  1620640000.0)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query('''SELECT * FROM POSTS ;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_posts = db.query('''SELECT TITLE FROM POSTS ;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = sample_posts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\n",
      "   Tokens: ['I', ',', 'too', ',', 'Y', '##OL', '##O', \"'\", 'D', 'my', 'retirement', 'account', 'into', 'GM', '##E', 'when', 'I', 'switched', 'jobs', '.', 'P', '##IC', '##K', 'ME', 'UP', 'ON', 'THE', 'WA', '##Y', 'TO', 'THE', 'M', '##O', '##O']\n",
      "Token IDs: [146, 117, 1315, 117, 162, 13901, 2346, 112, 141, 1139, 4406, 3300, 1154, 14748, 2036, 1165, 146, 6759, 5448, 119, 153, 9741, 2428, 22157, 19753, 21748, 7462, 22751, 3663, 16972, 7462, 150, 2346, 2346]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "encoding = tokenizer.encode_plus(\n",
    "    sample_txt,\n",
    "    #max_length=32,\n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   146,   117,  1315,   117,   162, 13901,  2346,   112,   141,\n",
       "          1139,  4406,  3300,  1154, 14748,  2036,  1165,   146,  6759,  5448,\n",
       "           119,   153,  9741,  2428, 22157, 19753, 21748,  7462, 22751,  3663,\n",
       "         16972,  7462,   150,  2346,  2346,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'I',\n",
       " ',',\n",
       " 'too',\n",
       " ',',\n",
       " 'Y',\n",
       " '##OL',\n",
       " '##O',\n",
       " \"'\",\n",
       " 'D',\n",
       " 'my',\n",
       " 'retirement',\n",
       " 'account',\n",
       " 'into',\n",
       " 'GM',\n",
       " '##E',\n",
       " 'when',\n",
       " 'I',\n",
       " 'switched',\n",
       " 'jobs',\n",
       " '.',\n",
       " 'P',\n",
       " '##IC',\n",
       " '##K',\n",
       " 'ME',\n",
       " 'UP',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'WA',\n",
       " '##Y',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'M',\n",
       " '##O',\n",
       " '##O',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.PRE_TRAINED_MODEL_NAME)\n",
    "        self.db = Database()\n",
    "        self.db.use_database('DB1')\n",
    "        self.indexes = self.db.query('''SELECT POST_ID FROM POSTS;''')\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indexes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        post = db.query(\"SELECT TITLE FROM POSTS WHERE POST_ID='{}'\".format(indexes[index][0]))[0][0]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            post,\n",
    "            max_length=self.max_len,\n",
    "            add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',  # Return PyTorch tensors\n",
    "            )\n",
    "        \n",
    "        return {\n",
    "            'post': post,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            #'targets': torch.tensor(target, dtype=torch.long)\n",
    "            }\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
