{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/stock-sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ianleefmans/Desktop/stock-sentiment/utils')\n",
    "from data import Database, ScrapeWSB, Stock\n",
    "from datahelper import PostDataset, CommentDataset, get_indices\n",
    "from torch.utils.data import DataLoader\n",
    "from models import FineTuneBaseModel\n",
    "%cd /Users/ianleefmans/Desktop/stock-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 2, 17, 16, 14),)]\n",
      "[('COMMENTS',), ('POSTS',), ('STOCKS',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "\n",
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nnpn9z',), ('nns6mk',), ('nn4aej',), ('nmpk6k',), ('nmjo2l',), ('nmabst',), ('nm53o9',), ('nmthag',), ('nmpq6d',)]\n"
     ]
    }
   ],
   "source": [
    "print(db.query(\"SELECT POST_ID FROM POSTS WHERE TARGET IN (0, 1)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GME', datetime.datetime(2021, 5, 31, 18, 8, 14))]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SELECT * FROM STOCKS ;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AMC & GME Price Action Comparison before their squeeze', -1),\n",
       " ('7k Loss on GME 0DTE', -1),\n",
       " ('GME & AMC', -1),\n",
       " ('AMC GME Meme ðŸš€ðŸŒ•', -1),\n",
       " ('Proper 401k weighting for a 26 year old? 99.8% $GME, 0.2% $AMC', -1),\n",
       " ('Happy to see everyone make it all back on GME and AMC... Anyone still holding BB like a retard? Make',\n",
       "  -1),\n",
       " ('For all of you retarded apes talking about the $GME $AMC short squeezing to the millions',\n",
       "  -1),\n",
       " ('Welp. Iâ€™ve been selling CCâ€™s on my GME to bring my cost basis down since January. I knew this day wo',\n",
       "  -1),\n",
       " ('What if GME does a OSTK.', -1),\n",
       " (\"I am an idiot. Wife doesn't know yet. Yolo'd into GME at the peak hoping to correct this loss.\",\n",
       "  -1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query('''SELECT TITLE, TARGET FROM POSTS;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hell yeah! now give me some coke.', 1),\n",
       " (\"Look, I don't even have a position in AMC anymore, but it's pretty clear this shit isn't over. Next week is gonna get crazy.\",\n",
       "  1),\n",
       " ('That was aggressive', -1),\n",
       " (\"Boys got a touch of the 'tardation\", -1),\n",
       " ('Iâ€™m not Fucking selling', -1),\n",
       " (\"With my crumb of the crop $525 buying in at $12.04....I'm holding till I can give my doggo the acreage he deserves yooo!!! Sploooge\",\n",
       "  -1),\n",
       " ('This is my hat now, totally my hat!!', -1),\n",
       " ('Hilarious movie btw', -1),\n",
       " (\"Haha, I'm always impressed with 20s something with this much cash. I'm 44 and had nothing like savings until mid 30s. Bravo\",\n",
       "  -1),\n",
       " ('Looks like you have unallocated cash?', -1),\n",
       " ('I mean, obviously this was getting removed\\n\\nEdit: changed our minds', -1),\n",
       " ('GME is NYSE....', -1),\n",
       " ('I am still holding BB w $20 average. Help me', -1),\n",
       " ('BB HOLDING STRONG!', -1),\n",
       " (\"But they are covered calls right?  You aren't down.  You are up.\", -1),\n",
       " (\"I rolled up and out.  I wrote 5/28 $200 cc and rolled to 7/16 $260 for additional premium.  \\nFigured if it's going to get called away, I wait 50 days to collect an additional $6000.\",\n",
       "  -1),\n",
       " ('OSTKâ€™s digital dividend definitely helped, but there are several factors that caused OSTK to hit $100+. That said, I think OSTK will hit $200+ within the next year.',\n",
       "  -1),\n",
       " (\"Half the people on here could have bought synthetic longs. Thats the problem. Citadel and Melvin sold shares they didn't have, they sold shares that don't exist.\",\n",
       "  -1),\n",
       " ('Next time buy on margin so you can be doubly retarded', -1),\n",
       " ('Tell your wife you have a prostitute addiction. Will go over better', -1)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query('''SELECT COMMENT, TARGET FROM COMMENTS;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT TITLE FROM POSTS WHERE POST_ID='{}' AND STOCK_ID='{}'\".format(indexes[0][0], 'GME'))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = db.query(\"SELECT POST_ID FROM POSTS WHERE StOCK_ID='{}';\".format(\"GME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT COUNT(*) FROM POSTS WHERE StOCK_ID='{}';\".format(\"GME\"))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 31, 18, 50, 59),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 5, 31, 18, 50, 59),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 31, 18, 51, 1),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:54<00:00, 11.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "#db.drop_table(\"LABELED_POSTS\")\n",
    "#db.drop_table(\"LABELED_COMMENTS\")\n",
    "\n",
    "db.initialize_tables()\n",
    "\n",
    "scrapewsb = ScrapeWSB('GME', 10, 2)\n",
    "\n",
    "df = scrapewsb.scrape()\n",
    "scrapewsb.convert(df)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 30, 0, 20, 6),)]\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "db.use_database('DB1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('POSTS',)]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nnpn9z',), ('nn4aej',), ('nns6mk',), ('nmpk6k',), ('nmjo2l',), ('nm53o9',), ('nmabst',), ('nmthag',), ('nmmu24',), ('nmpq6d',)]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SELECT POST_ID FROM POSTS WHERE TARGET=-1 ;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('POST_ID', b'char(20)', 'NO', '', None, ''), ('TARGET', b'int', 'YES', '', None, ''), ('TITLE', b'char(100)', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SHOW COLUMNS FROM LABELED_POSTS;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table(\"LABELED_POSTS\")\n",
    "db.drop_table(\"LABELED_COMMENTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table('COMMENTS')\n",
    "db.drop_table(\"POSTS\")\n",
    "db.drop_table(\"STOCKS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 2, 17, 22, 23),)]\n"
     ]
    }
   ],
   "source": [
    "indices = get_indices(\"no_stock_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 2, 17, 22, 24),)]\n"
     ]
    }
   ],
   "source": [
    "post_train = PostDataset(512, indices['post_train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trainloader = DataLoader(\n",
    "    dataset=post_train, \n",
    "    batch_size=3, \n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "sample = iter(post_trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': ['GME & AMC',\n",
       "  'What if GME does a OSTK.',\n",
       "  'Proper 401k weighting for a 26 year old? 99.8% $GME, 0.2% $AMC'],\n",
       " 'post_input_ids': tensor([[  101, 14748,  2036,  ...,     0,     0,     0],\n",
       "         [  101,  1327,  1191,  ...,     0,     0,     0],\n",
       "         [  101,  5096,  3365,  ...,     0,     0,     0]]),\n",
       " 'post_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'target': tensor([[[0., 1.]],\n",
       " \n",
       "         [[1., 0.]],\n",
       " \n",
       "         [[0., 1.]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['target'].reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "_, ground_truths = torch.max(sample['target'].reshape(-1,2), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.6015,  0.3814,  0.9997,  ...,  0.9999, -0.6898,  0.9579],\n",
      "        [-0.6080,  0.4887,  0.9999,  ...,  1.0000, -0.9328,  0.9946],\n",
      "        [-0.5415,  0.3671,  0.9996,  ...,  0.9998, -0.7365,  0.9712]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = FineTuneBaseModel()\n",
    "\n",
    "out = model(input_ids=sample['post_input_ids'], attention_masks=sample['post_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7030, 0.2970],\n",
       "        [0.7028, 0.2972],\n",
       "        [0.7087, 0.2913]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, preds = torch.max(out, dim=1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(preds==ground_truths)/len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.Tensor([1, 0]).reshape(1,2).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-993b667511e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "label = torch.Tensor([torch.Tensor([0, 1]).reshape(1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
