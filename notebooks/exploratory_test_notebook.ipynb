{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/stock-sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ianleefmans/Desktop/stock-sentiment/utils')\n",
    "from data import Database, ScrapeWSB, Stock\n",
    "from datahelper import PostDataset, CommentDataset, get_indices\n",
    "from torch.utils.data import DataLoader\n",
    "from inference import RunInference\n",
    "from models import FineTuneBaseModel, FineTuneClassifier\n",
    "%cd /Users/ianleefmans/Desktop/stock-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 18, 22, 44),)]\n",
      "[('COMMENTS',), ('POSTS',), ('STOCKS',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "\n",
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AMC', datetime.datetime(2021, 6, 6, 22, 15, 44))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT * FROM STOCKS WHERE STOCK_ID='AMC' AND LAST_SCRAPED >= DATE_SUB(NOW(),INTERVAL 55 MINUTE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nx2ihx',),\n",
       " ('nxcb5h',),\n",
       " ('nxp5r6',),\n",
       " ('nxtjj4',),\n",
       " ('nxv9jr',),\n",
       " ('nxx9sz',),\n",
       " ('ny01wx',),\n",
       " ('nz6tgd',),\n",
       " ('nzf0mj',),\n",
       " ('nzjcfg',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT POST_ID FROM POSTS WHERE STOCK_ID='{}' AND LAST_SCRAPED >= DATE_SUB((SELECT LAST_SCRAPED FROM STOCKS WHERE STOCK_ID = '{}'), INTERVAL {} HOUR);\".format('BB', 'BB', 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nv0h06',)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT POST_ID FROM POSTS WHERE STOCK_ID='{}' AND LAST_SCRAPED >= DATE_SUB((SELECT LAST_SCRAPED FROM STOCKS WHERE STOCK_ID = '{}'),INTERVAL {} HOUR);\".format('AAPL','AAPL',6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2021, 6, 14, 18, 21, 27),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT LAST_SCRAPED FROM POSTS WHERE LAST_SCRAPED >= DATE_SUB((SELECT LAST_SCRAPED FROM STOCKS WHERE STOCK_ID = 'AAPL'),INTERVAL 6 HOUR);\")\n",
    "         \n",
    "         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mzzf2q', datetime.datetime(2021, 6, 7, 1, 38, 7)),\n",
       " ('n0ivmx', datetime.datetime(2021, 6, 7, 1, 38, 7)),\n",
       " ('n1kq5z', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n226xb', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n2guu3', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n3m6m0', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('n51zx5', datetime.datetime(2021, 6, 7, 1, 38, 7)),\n",
       " ('n5sglk', datetime.datetime(2021, 6, 7, 1, 38, 7)),\n",
       " ('n6991f', datetime.datetime(2021, 6, 7, 1, 38, 7)),\n",
       " ('n6fa9f', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('n6k7wf', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n6m3qj', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('n799ne', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n7fe53', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n8coni', datetime.datetime(2021, 6, 7, 1, 38, 6)),\n",
       " ('n8mv7h', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('n90iyg', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('n93o6x', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('na8f8j', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('namvm5', datetime.datetime(2021, 6, 7, 1, 38, 4)),\n",
       " ('nbjqzf', datetime.datetime(2021, 6, 7, 1, 38, 5)),\n",
       " ('nekymm', datetime.datetime(2021, 6, 7, 1, 38, 4)),\n",
       " ('nggpql', datetime.datetime(2021, 6, 7, 1, 38, 4)),\n",
       " ('nh66wz', datetime.datetime(2021, 6, 7, 1, 38, 4)),\n",
       " ('nh6ijq', datetime.datetime(2021, 6, 7, 1, 38, 4)),\n",
       " ('njoxij', datetime.datetime(2021, 6, 7, 1, 38, 4)),\n",
       " ('nolej2', datetime.datetime(2021, 6, 7, 1, 38, 3)),\n",
       " ('nquul5', datetime.datetime(2021, 6, 7, 1, 38, 3)),\n",
       " ('nrnkge', datetime.datetime(2021, 6, 7, 1, 38, 3)),\n",
       " ('nv0h06', datetime.datetime(2021, 6, 14, 18, 21, 27))]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT POST_ID, LAST_SCRAPED FROM POSTS WHERE STOCK_ID='AAPL'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = db.query(\"SELECT POST_ID FROM POSTS WHERE StOCK_ID='{}';\".format(\"GME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 6, 17, 23, 59),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 6, 17, 24),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 6, 17, 24, 3),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 11/11 [01:08<00:00,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "#db.drop_table(\"LABELED_POSTS\")\n",
    "#db.drop_table(\"LABELED_COMMENTS\")\n",
    "\n",
    "db.initialize_tables()\n",
    "\n",
    "scrapewsb = ScrapeWSB('GME', 11, 2)\n",
    "\n",
    "df = scrapewsb.scrape()\n",
    "scrapewsb.convert(df)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 30, 0, 20, 6),)]\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "db.use_database('DB1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table('COMMENTS')\n",
    "db.drop_table(\"POSTS\")\n",
    "db.drop_table(\"STOCKS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 15, 21, 47, 15),)]\n"
     ]
    }
   ],
   "source": [
    "indices = get_indices(\"BB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 15, 21, 47, 18),)]\n"
     ]
    }
   ],
   "source": [
    "post_train = PostDataset(512, indices['post_train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trainloader = DataLoader(\n",
    "    dataset=post_train, \n",
    "    batch_size=3, \n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "sample = iter(post_trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': ['(Part 2) AMC & GME Price Action Comparison before their squeeze',\n",
       "  'â—â€œThe Monkey Foolâ€â— ðŸ¤¡: A Parody on How Bullsh!t FUD Campaigns Are Made for GameStop ðŸ˜¹ A Professional',\n",
       "  'AMC YOLO LFG!'],\n",
       " 'post_input_ids': tensor([[  101,   113,  4539,  ...,     0,     0,     0],\n",
       "         [  101,   100,   789,  ...,     0,     0,     0],\n",
       "         [  101, 24810,   162,  ...,     0,     0,     0]]),\n",
       " 'post_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'target': tensor([0, 0, 1])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = FineTuneClassifier()\n",
    "\n",
    "out = model(input_ids=sample['post_input_ids'], attention_masks=sample['post_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5016, 0.4984],\n",
       "        [0.5107, 0.4893],\n",
       "        [0.4868, 0.5132]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pos = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5132220983505249"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(out[:,1].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pos[float(out[:,1].max())] = sample['post'][int(out[:,1].argmax())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.5132220983505249: 'AMC YOLO LFG!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 30),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Determining Sentiment From Posts:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 32),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 33),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 33),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 34),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 34),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 35),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 35),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 36),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 36),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 37),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 14, 17, 1, 37),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determining Sentiment From Posts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:21<00:00, 21.32s/it]\n",
      "Determining Sentiment From Comments: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:39<00:00, 49.56s/it]\n"
     ]
    }
   ],
   "source": [
    "run_inference = RunInference(stock_id='BB')\n",
    "inference_output = run_inference.evaluate()\n",
    "\n",
    "post_probs = inference_output['avg_post_probs']\n",
    "\n",
    "comment_probs = inference_output['avg_comment_probs']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
