{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/stock-sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ianleefmans/Desktop/stock-sentiment/utils')\n",
    "from data import Database, ScrapeWSB, Stock\n",
    "%cd /Users/ianleefmans/Desktop/stock-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 27, 19, 36, 58),)]\n",
      "[('COMMENTS',), ('POSTS',), ('STOCKS',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "\n",
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GME', datetime.datetime(2021, 5, 14, 1, 43, 41))]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SELECT * FROM STOCKS ;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_posts = db.query('''SELECT TITLE FROM POSTS ;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_txt = sample_posts[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sentence: I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\n",
      "   Tokens: ['I', ',', 'too', ',', 'Y', '##OL', '##O', \"'\", 'D', 'my', 'retirement', 'account', 'into', 'GM', '##E', 'when', 'I', 'switched', 'jobs', '.', 'P', '##IC', '##K', 'ME', 'UP', 'ON', 'THE', 'WA', '##Y', 'TO', 'THE', 'M', '##O', '##O']\n",
      "Token IDs: [146, 117, 1315, 117, 162, 13901, 2346, 112, 141, 1139, 4406, 3300, 1154, 14748, 2036, 1165, 146, 6759, 5448, 119, 153, 9741, 2428, 22157, 19753, 21748, 7462, 22751, 3663, 16972, 7462, 150, 2346, 2346]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sample_txt)\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(f' Sentence: {sample_txt}')\n",
    "print(f'   Tokens: {tokens}')\n",
    "print(f'Token IDs: {token_ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "encoding = tokenizer.encode_plus(\n",
    "    sample_txt,\n",
    "    #max_length=32,\n",
    "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
    "    return_token_type_ids=False,\n",
    "    pad_to_max_length=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt',  # Return PyTorch tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,   146,   117,  1315,   117,   162, 13901,  2346,   112,   141,\n",
       "          1139,  4406,  3300,  1154, 14748,  2036,  1165,   146,  6759,  5448,\n",
       "           119,   153,  9741,  2428, 22157, 19753, 21748,  7462, 22751,  3663,\n",
       "         16972,  7462,   150,  2346,  2346,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'I',\n",
       " ',',\n",
       " 'too',\n",
       " ',',\n",
       " 'Y',\n",
       " '##OL',\n",
       " '##O',\n",
       " \"'\",\n",
       " 'D',\n",
       " 'my',\n",
       " 'retirement',\n",
       " 'account',\n",
       " 'into',\n",
       " 'GM',\n",
       " '##E',\n",
       " 'when',\n",
       " 'I',\n",
       " 'switched',\n",
       " 'jobs',\n",
       " '.',\n",
       " 'P',\n",
       " '##IC',\n",
       " '##K',\n",
       " 'ME',\n",
       " 'UP',\n",
       " 'ON',\n",
       " 'THE',\n",
       " 'WA',\n",
       " '##Y',\n",
       " 'TO',\n",
       " 'THE',\n",
       " 'M',\n",
       " '##O',\n",
       " '##O',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, max_len):\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "    def __getitem__(self):\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
