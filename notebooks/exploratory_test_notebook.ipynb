{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/stock-sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ianleefmans/Desktop/stock-sentiment/utils')\n",
    "from data import Database, ScrapeWSB, Stock\n",
    "from datahelper import PostDataset, CommentDataset, get_indices\n",
    "from torch.utils.data import DataLoader\n",
    "from models import FineTuneBaseModel\n",
    "%cd /Users/ianleefmans/Desktop/stock-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 5, 3, 8, 2),)]\n",
      "[('COMMENTS',), ('POSTS',), ('STOCKS',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "\n",
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nnpn9z',), ('nns6mk',), ('nn4aej',), ('nmpk6k',), ('nmjo2l',), ('nmabst',), ('nm53o9',), ('nmthag',), ('nmpq6d',)]\n"
     ]
    }
   ],
   "source": [
    "print(db.query(\"SELECT POST_ID FROM POSTS WHERE TARGET IN (0, 1)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('GME', datetime.datetime(2021, 5, 31, 18, 8, 14))]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SELECT * FROM STOCKS ;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Current Price Action of GME is shockingly similar to the past two major run-ups and 'micro squeezes'\",\n",
       "  1),\n",
       " (\"Added $165K more to the GME July 800s YOLO - $646K at risk let's GOOOOO\",\n",
       "  0),\n",
       " ('Ape wonders about AMC,GME and BB advertising budget üôâüöÄ SpaceX', 1),\n",
       " ('Another $GME, $AMC, $BB aimed for the MOON', 0),\n",
       " ('We like the stock $AMC $GME', 1),\n",
       " ('Is $SNDL going to do the amc/gme? üöÄ', 0),\n",
       " ('GME to the moon!!! And sometimes bananas fuck assholes!!! üíéüôåü¶ç', 1),\n",
       " ('Lets Go!!! GME to the moon!!!', 0),\n",
       " ('The Gang Buys $GME', 1),\n",
       " ('Fresh out of the womb tube here gentlemen! I missed GME. I missed AMC. Putting my toes in the water',\n",
       "  0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query('''SELECT TITLE, TARGET FROM POSTS;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"6/9....it's only fitting\", 0),\n",
       " ('Damn I love GME', 0),\n",
       " (\"Somethin ain't right here...  \\n\\n\\n  Your wife has a *girlfriend*?\", 1),\n",
       " (\"This guy has a fully charged phone?!?!?! Something doesn't add up\", 0),\n",
       " ('BB is buckling up. Let‚Äôs go üöÄüöÄüöÄ', 1),\n",
       " ('Lol, this would be great.\\nTweet @KatStryker111 she is the ape advertisement queen',\n",
       "  0),\n",
       " ('Busy, check back in 2 weeks.', 1),\n",
       " ('\"TO RISE FOR THE NEXT DECADE\"  \\n\\n\\nBitch if it aint rising by next week then I DONT WANT IT.',\n",
       "  0),\n",
       " ('Here before this gets yeeted', 1),\n",
       " ('280$ next week just like that guy predicted', 0),\n",
       " ('We want $SNDL  \\nWe want $SNDL  \\nWe want $SNDL', 1),\n",
       " (\"I don't know if I can trust you with a fully charged battery. ü§î\", 0),\n",
       " ('Name me a better motivational speech... I dare you....', 1),\n",
       " ('Now I have to watch team America again, Trey and Matt are fucking legendary!!!!!',\n",
       "  0),\n",
       " ('FUCK YEAH!!!', 1),\n",
       " ('Stonk Market Ape Police', 0),\n",
       " ('I‚Äôve seen so many memes of this show that I may just as well start watching it.',\n",
       "  1),\n",
       " ('I will always upvote always Sunny!', 0),\n",
       " ('You did not miss GME, January was only a baby squeeze', 1),\n",
       " ('Every stock is a depression related stock when you lose all your money to it!',\n",
       "  0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query('''SELECT COMMENT, TARGET FROM COMMENTS;''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I, too, YOLO'D my retirement account into GME when I switched jobs. PICK ME UP ON THE WAY TO THE MOO\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT TITLE FROM POSTS WHERE POST_ID='{}' AND STOCK_ID='{}'\".format(indexes[0][0], 'GME'))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = db.query(\"SELECT POST_ID FROM POSTS WHERE StOCK_ID='{}';\".format(\"GME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT COUNT(*) FROM POSTS WHERE StOCK_ID='{}';\".format(\"GME\"))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 5, 0, 40, 6),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 6, 5, 0, 40, 7),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 5, 0, 40, 9),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:45<00:00, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "#db.drop_table(\"LABELED_POSTS\")\n",
    "#db.drop_table(\"LABELED_COMMENTS\")\n",
    "\n",
    "db.initialize_tables()\n",
    "\n",
    "scrapewsb = ScrapeWSB('GME', 10, 2)\n",
    "\n",
    "df = scrapewsb.scrape()\n",
    "scrapewsb.convert(df)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 5, 30, 0, 20, 6),)]\n"
     ]
    }
   ],
   "source": [
    "db = Database()\n",
    "db.use_database('DB1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('POSTS',)]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('nnpn9z',), ('nn4aej',), ('nns6mk',), ('nmpk6k',), ('nmjo2l',), ('nm53o9',), ('nmabst',), ('nmthag',), ('nmmu24',), ('nmpq6d',)]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SELECT POST_ID FROM POSTS WHERE TARGET=-1 ;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('POST_ID', b'char(20)', 'NO', '', None, ''), ('TARGET', b'int', 'YES', '', None, ''), ('TITLE', b'char(100)', 'YES', '', None, '')]\n"
     ]
    }
   ],
   "source": [
    "print(db.query('''SHOW COLUMNS FROM LABELED_POSTS;'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table(\"LABELED_POSTS\")\n",
    "db.drop_table(\"LABELED_COMMENTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.drop_table('COMMENTS')\n",
    "db.drop_table(\"POSTS\")\n",
    "db.drop_table(\"STOCKS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 2, 17, 22, 23),)]\n"
     ]
    }
   ],
   "source": [
    "indices = get_indices(\"no_stock_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 6, 2, 17, 22, 24),)]\n"
     ]
    }
   ],
   "source": [
    "post_train = PostDataset(512, indices['post_train'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trainloader = DataLoader(\n",
    "    dataset=post_train, \n",
    "    batch_size=3, \n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "sample = iter(post_trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': ['GME & AMC',\n",
       "  'What if GME does a OSTK.',\n",
       "  'Proper 401k weighting for a 26 year old? 99.8% $GME, 0.2% $AMC'],\n",
       " 'post_input_ids': tensor([[  101, 14748,  2036,  ...,     0,     0,     0],\n",
       "         [  101,  1327,  1191,  ...,     0,     0,     0],\n",
       "         [  101,  5096,  3365,  ...,     0,     0,     0]]),\n",
       " 'post_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'target': tensor([[[0., 1.]],\n",
       " \n",
       "         [[1., 0.]],\n",
       " \n",
       "         [[0., 1.]]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.6015,  0.3814,  0.9997,  ...,  0.9999, -0.6898,  0.9579],\n",
      "        [-0.6080,  0.4887,  0.9999,  ...,  1.0000, -0.9328,  0.9946],\n",
      "        [-0.5415,  0.3671,  0.9996,  ...,  0.9998, -0.7365,  0.9712]],\n",
      "       grad_fn=<TanhBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = FineTuneBaseModel()\n",
    "\n",
    "out = model(input_ids=sample['post_input_ids'], attention_masks=sample['post_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7030, 0.2970],\n",
       "        [0.7028, 0.2972],\n",
       "        [0.7087, 0.2913]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
