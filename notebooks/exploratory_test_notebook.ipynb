{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/Desktop/stock-sentiment\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/ianleefmans/Desktop/stock-sentiment/utils')\n",
    "from data import Database, ScrapeWSB, Stock\n",
    "from datahelper import PostDataset, CommentDataset, get_indices\n",
    "from torch.utils.data import DataLoader\n",
    "from inference import RunInference\n",
    "from models import FineTuneBaseModel, FineTuneClassifier\n",
    "%cd /Users/ianleefmans/Desktop/stock-sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DB Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 10, 6, 18, 26, 27),)]\n",
      "[('COMMENTS',), ('POSTS',), ('STOCKS',)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "db = Database()\n",
    "db.use_database('DB1')\n",
    "\n",
    "print(db.query('show tables;'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AMC', datetime.datetime(2021, 6, 6, 22, 15, 44))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT * FROM STOCKS WHERE STOCK_ID='AMC' AND LAST_SCRAPED >= DATE_SUB(NOW(),INTERVAL 55 MINUTE)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nx2ihx',),\n",
       " ('nxcb5h',),\n",
       " ('nxp5r6',),\n",
       " ('nxtjj4',),\n",
       " ('nxv9jr',),\n",
       " ('nxx9sz',),\n",
       " ('ny01wx',),\n",
       " ('nz6tgd',),\n",
       " ('nzf0mj',),\n",
       " ('nzjcfg',)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT POST_ID FROM POSTS WHERE STOCK_ID='{}' AND LAST_SCRAPED >= DATE_SUB((SELECT LAST_SCRAPED FROM STOCKS WHERE STOCK_ID = '{}'), INTERVAL {} HOUR);\".format('BB', 'BB', 6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nv0h06',)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT POST_ID FROM POSTS WHERE STOCK_ID='{}' AND LAST_SCRAPED >= DATE_SUB((SELECT LAST_SCRAPED FROM STOCKS WHERE STOCK_ID = '{}'),INTERVAL {} HOUR);\".format('AAPL','AAPL',6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.datetime(2021, 6, 14, 18, 21, 27),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 44),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),),\n",
       " (datetime.datetime(2021, 6, 14, 14, 27, 43),)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.query(\"SELECT LAST_SCRAPED FROM POSTS WHERE LAST_SCRAPED >= DATE_SUB((SELECT LAST_SCRAPED FROM STOCKS WHERE STOCK_ID = 'AAPL'),INTERVAL 6 HOUR);\")\n",
    "         \n",
    "         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 10, 6, 19, 48, 59),)]\n"
     ]
    }
   ],
   "source": [
    "indices = get_indices(\"GME\", inference=True, scrape_time=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 10, 6, 19, 49, 1),)]\n"
     ]
    }
   ],
   "source": [
    "post_train = PostDataset(512, indices['post_ids'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_trainloader = DataLoader(\n",
    "    dataset=post_train, \n",
    "    batch_size=3, \n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = iter(post_trainloader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': ['GIANT $RUN LOVING APE BALLS OUT.....$BB $AMC $GME',\n",
       "  'Jim Cramer WSB FOMO- GME and AMC bull!',\n",
       "  'Daily option statistics for AMC, CLNE, BB, WISH, GME, WKHS, CLOV, PLTR, CLF, and others.'],\n",
       " 'post_input_ids': tensor([[ 101,  144, 9984,  ...,    0,    0,    0],\n",
       "         [ 101, 3104,  140,  ...,    0,    0,    0],\n",
       "         [ 101, 5732, 5146,  ...,    0,    0,    0]]),\n",
       " 'post_attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'target': tensor([-1, -1, -1]),\n",
       " 'date': tensor([1.6240e+09, 1.6240e+09, 1.6240e+09], dtype=torch.float64)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = FineTuneClassifier()\n",
    "\n",
    "out = model(input_ids=sample['post_input_ids'], attention_masks=sample['post_attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5016, 0.4984],\n",
       "        [0.5107, 0.4893],\n",
       "        [0.4868, 0.5132]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 10, 16, 20, 2, 31),)]\n",
      "connection established\n",
      "[(datetime.datetime(2021, 10, 16, 20, 2, 33),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Determining Sentiment From Posts:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "connection established\n",
      "[(datetime.datetime(2021, 10, 16, 20, 2, 35),)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Determining Sentiment From Posts: 100%|██████████| 1/1 [00:10<00:00, 10.36s/it]\n",
      "Determining Sentiment From Comments: 100%|██████████| 1/1 [00:10<00:00, 10.34s/it]\n"
     ]
    }
   ],
   "source": [
    "from inference import RunInference\n",
    "\n",
    "run =RunInference('GME')\n",
    "output = run.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'avg_post_probs': tensor([0.3999, 0.6001]),\n",
       " 'avg_comment_probs': tensor([0.7995, 0.2005]),\n",
       " 'all_post_probs': tensor([[9.9936e-01, 6.3518e-04],\n",
       "         [2.2896e-04, 9.9977e-01],\n",
       "         [2.2188e-04, 9.9978e-01],\n",
       "         [9.9945e-01, 5.4841e-04],\n",
       "         [1.7562e-04, 9.9982e-01]]),\n",
       " 'all_comment_probs': tensor([[9.9924e-01, 7.5561e-04],\n",
       "         [3.0345e-04, 9.9970e-01],\n",
       "         [9.9924e-01, 7.5804e-04],\n",
       "         [9.9927e-01, 7.3070e-04],\n",
       "         [9.9933e-01, 6.6655e-04]]),\n",
       " 'all_post_dates': tensor([1.6336e+09, 1.6335e+09, 1.6336e+09, 1.6335e+09, 1.6336e+09],\n",
       "        dtype=torch.float64),\n",
       " 'all_comment_dates': tensor([1.6336e+09, 1.6335e+09, 1.6336e+09, 1.6335e+09, 1.6336e+09],\n",
       "        dtype=torch.float64),\n",
       " 'max_post_prob': 0.9998244643211365,\n",
       " 'max_comment_prob': 0.9996966123580933,\n",
       " 'max_post': '$77K to $233K, Roller coaster journey. Top Gainers: GME, SPCE, DOCN, ASAN, WORK, SPOT',\n",
       " 'max_comment': \"Alright SDC, if you can multiply your stock price by 100 right now, I will be a millionaire and can get myself a FAT lake house. Let's go baby!\",\n",
       " 'min_post_prob': 0.0005484112771227956,\n",
       " 'min_comment_prob': 0.0006665491964668036,\n",
       " 'min_post': 'Here is my FB position I covered today had to take the gains the hidden part is GME can’t wait to sh',\n",
       " 'min_comment': 'All I want is a 300% run. What’s the big deal?'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 722/722 [00:01<00:00, 425.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from forecast import Forecast\n",
    "\n",
    "get_stock = Forecast(\"GME\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Constant Sentiment, Random Noise Added\n"
     ]
    }
   ],
   "source": [
    "preds = get_stock.arima(periods=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = ARIMA(endog=data.close, exog = self.stock_data.highlow_percent, order=(1, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "mod = ARIMA(endog=data.sentiment, order=(1, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "res = mod.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "def pred(df, count):\n",
    "    if count == 0:\n",
    "        return\n",
    "    \n",
    "    mod = ARIMA(endog=df, order=(1, 0, 0))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    predictions.append(float(res.forecast()))\n",
    "    \n",
    "    \n",
    "    pred(df+[float(res.forecast())], count-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n",
      "/Users/ianleefmans/opt/anaconda3/envs/StockSentiment/lib/python3.7/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "pred(list(data.sentiment), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7995407913533179,\n",
       " 0.7995407770139782,\n",
       " 0.7995407793797036,\n",
       " 0.7995407826003444,\n",
       " 0.7995407878415857,\n",
       " 0.7995407945813624,\n",
       " 0.7995408025039776,\n",
       " 0.7995408113972577,\n",
       " 0.7995408211084032,\n",
       " 0.7995408315218733]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = []\n",
    "def pred2(df1, df2):\n",
    "    if len(df1)==len(df2):\n",
    "        return\n",
    "    \n",
    "    mod = ARIMA(endog=df1, exog = df2[0:len(df1), 0], order=(1, 0, 0))\n",
    "    res = mod.fit()\n",
    "    \n",
    "    predictions2.append(res.forecast(exog=[df2[len(df1)-1, 0]]))\n",
    "    \n",
    "    \n",
    "    pred2(df1+[float(res.forecast(exog=[df2[len(df1)-1, 0]]))], df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2(list(data.close), np.add(np.array(list(data.sentiment)+predictions).reshape(-1, 1), np.random.randn(len(list(data.sentiment)+predictions), 1).reshape(-1, 1)))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
